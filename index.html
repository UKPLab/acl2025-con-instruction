<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Con Instruct: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities">
  <meta property="og:title" content="Con Instruct: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities"/>
  <meta property="og:description" content="LLM,VLLM,MLLM,LLM Attack,LLM Safety, MLLM Safety"/>
  <meta property="og:url" content="https://ukplab.github.io/acl2025-con-instruction/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="LLM Attack,LLM Safety, MLLM Safety, LLM, MLLM, VLM">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Con Instruct: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Con Instruct: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=eMC-gQUAAAAJ&hl=en" target="_blank">Jiahui Geng</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://www.informatik.tu-darmstadt.de/ukp/ukp_home/staff_ukp/ukp_home_content_staff_1_details_107392.en.jsp" target="_blank">Thy Thy Tran</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://mbzuai.ac.ae/study/faculty/preslav-nakov/" target="_blank">Preslav Nakov</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.informatik.tu-darmstadt.de/ukp/ukp_home/head_ukp/index.en.jsp" target="_blank">Iryna Gurevych</a><sup>1,2</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>MBZUAI&emsp;
                      <sup>2</sup>UKP Lab, TU Darmstadt &emsp;
                    </span>
                  </div>
            
                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      The 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025)</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://openreview.net/pdf?id=Xl8ItHKUhJ" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/UKPLab/acl2025-con-instruction/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3 has-text-centered">What is a Con Instructionüï¥Ô∏è?</h2>
      <h2 class="subtitle has-text-justified">
        A "conüï¥Ô∏è" instruction embedded in non-textual inputs (images or audio) that can quietly steer the model's behaviour.
        We optimize such "con" instruction (an image in this figure) by making it close to the target textual instruction in the joint embedding space. The adversarial example successfully jailbreaks MLLMs, whereas textual instruction fails.
      </h2>
      <img src="assets/intro.png" width="50%"/>
      <h2 class="hero-body has-text-centered">
        Illustration of Con Instruction
      </h2>
    </div>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Existing attacks against multimodal language models (MLLMs) primarily communicate instructions through text accompanied by adversarial images. In contrast, here we exploit the capabilities of MLLMs to interpret non-textual instructions‚Äìspecifically adversarial images or audio‚Äìgenerated by our novel method, Con Instruction. We optimize the adversarial examples to align closely with target instructions in the embedding space, revealing the detrimental aspects of sophisticated understanding in MLLMs. Unlike previous work, our method does not require training data or preprocessing of textual instructions. While these nontextual adversarial examples can effectively bypass MLLMs safety mechanisms, their combination with various text inputs substantially amplifies attack success. We further introduce a new attack response categorization (ARC) that considers both response quality and relevance to the malicious instructions to evaluate attack success. The results show that Con Instruction effectively bypasses the safety mechanisms in various visual and audio-language models, including LLaVA-v1.5, InternVL, Qwen-VL, and Qwen-Audio, across two standard benchmarks: AdvBench and SafeBench. Specifically, our method achieves the highest attack success rates, reaching 81.3% and 86.6% on LLaVAv1.5 (13B). On the defense side, we explore various methods against our attacks and find a substantial gap among existing techniques.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- method -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-sixths">
        <h2 class="title is-3">Overview of Con Instruction</h2>
        <img src="assets/illustration.png" width="80%"/>
        <h2 class="content has-text-justified">
          Overview of Con Instruction. In the first stage, adversarial samples are iteratively optimized to align visual token embeddings with text token embeddings, embedding malicious intent into images or audio. In the second stage, these adversarial samples, paired with benign text inputs such as empty strings, trigger a successful jailbreak while evading detection.
        </h2>
        
      </div>
    </div>
  </div>
</section>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{geng2025coninstruction,
          title={Con Instruction: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities},
          author={Geng, Jiahui and Tran, Thy Thy and Nakov, Preslav and Gurevych, Iryna},
          booktitle = "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics",
          year={2025},
          publisher = "Association for Computational Linguistics",
          url={https://openreview.net/forum?id=Xl8ItHKUhJ}
        }
        </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>
</html>
